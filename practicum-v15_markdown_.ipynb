{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the setting of different environment, the installing method of packages is different.\n",
    "\n",
    "\n",
    "If the system is windows, open the command prompt and type:\n",
    "\n",
    "\n",
    "\"pip install category_encoders\n",
    "\n",
    "\n",
    "pip install nltk\"\n",
    "(If the system is equipped with pip).\n",
    "\n",
    "\n",
    "Or, open the anaconda prompt and type:\n",
    "\n",
    "\n",
    "\"conda install -c conda-forge category_encoders \n",
    "\n",
    "\n",
    "conda install -c anaconda nltk \"\n",
    "(If the system is equipped with anaconda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (1.3.0)\n",
      "Requirement already satisfied: pandas>=0.20.1 in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (from category_encoders) (0.23.4)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (from category_encoders) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (from category_encoders) (0.20.0)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (from category_encoders) (0.8.0)\n",
      "Requirement already satisfied: patsy>=0.4.1 in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (from category_encoders) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (from category_encoders) (1.15.4)\n",
      "Requirement already satisfied: pytz>=2011k in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (from pandas>=0.20.1->category_encoders) (2017.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (from pandas>=0.20.1->category_encoders) (2.6.1)\n",
      "Requirement already satisfied: six in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (from patsy>=0.4.1->category_encoders) (1.10.0)\n",
      "Requirement already satisfied: nltk in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (3.2.4)\n",
      "Requirement already satisfied: six in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (from nltk) (1.10.0)\n"
     ]
    }
   ],
   "source": [
    "# For the system of Linux\n",
    "! pip install --user category_encoders\n",
    "! pip install --user nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (1.3.0)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (from category_encoders) (0.20.0)\n",
      "Requirement already satisfied: pandas>=0.20.1 in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (from category_encoders) (0.23.4)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (from category_encoders) (1.1.0)\n",
      "Requirement already satisfied: patsy>=0.4.1 in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (from category_encoders) (0.4.1)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (from category_encoders) (0.8.0)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (from category_encoders) (1.15.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (from pandas>=0.20.1->category_encoders) (2.6.1)\n",
      "Requirement already satisfied: pytz>=2011k in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (from pandas>=0.20.1->category_encoders) (2017.2)\n",
      "Requirement already satisfied: six in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (from patsy>=0.4.1->category_encoders) (1.10.0)\n",
      "Requirement already satisfied: nltk in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (3.2.4)\n",
      "Requirement already satisfied: six in /Users/zengweihao/anaconda3/lib/python3.6/site-packages (from nltk) (1.10.0)\n"
     ]
    }
   ],
   "source": [
    "# For the system of Mac\n",
    "! pip install category_encoders\n",
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk.stem\n",
    "from datetime import datetime as dt\n",
    "import category_encoders as ce\n",
    "\n",
    "#np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset. The training set are records since 2012 with manual labels, and the test set are raw records since 2012 without labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of the original dataset: \n",
    "https://www-odi.nhtsa.dot.gov/downloads/folders/Complaints/CMPL.txt\n",
    "\n",
    "The dataset (with manual labels) is avaiable in this address:\n",
    "https://drive.google.com/file/d/17SeAmFO6nXGVDW5-uzwXjUNWt58lZv2r/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zengweihao/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (29,37,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('datasince2012_train+test.csv',encoding='latin-1',error_bad_lines=False)\n",
    "train = data[data['batch']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To automate the future ADAS-related complaiint identified process, the model should be able to predict the future based on current information, then a time series split is needed for the model evaluation. Before we manipulate the data, we reorder the data by the report date, so that we can perform time series split directly later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20111022\n",
       "1    20111115\n",
       "2    20120106\n",
       "3    20120130\n",
       "4    20120225\n",
       "Name: DATEA, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.sort_values(by=['DATEA'])\n",
    "train['DATEA'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = data[data['batch']==2]\n",
    "test = test.loc[(test['FAILDATE'] >= 20120101) & (test['FAILDATE'] <= 20190000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the size of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size is : (157602, 61)\n"
     ]
    }
   ],
   "source": [
    "ntrain = train.shape[0]\n",
    "data = pd.concat([train, test], sort = False).reset_index(drop=True)\n",
    "print(\"data size is : {}\".format(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2496, 61)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155106, 61)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                                  2495\n",
       "CMPLID                                                                   1494245\n",
       "ODINO                                                                   11124051\n",
       "MFR_NAME                                                   Chrysler (FCA US LLC)\n",
       "MAKETXT                                                                      RAM\n",
       "MODELTXT                                                                    1500\n",
       "YEARTXT                                                                     2013\n",
       "CRASH                                                                          N\n",
       "FAILDATE                                                                20180810\n",
       "FIRE                                                                           N\n",
       "INJURED                                                                      NaN\n",
       "DEATHS                                                                       NaN\n",
       "COMPDESC                                                       electrical system\n",
       "CITY                                                                     HOUSTON\n",
       "STATE                                                                         TX\n",
       "VIN                                                                  1C6RR7LT0DS\n",
       "DATEA                                                                   20180902\n",
       "LDATE                                                                   20180902\n",
       "MILES                                                                      60000\n",
       "OCCURENCES                                                                   NaN\n",
       "CDESCR                         as i was parking my vehicle i heard a click so...\n",
       "CMPL_TYPE                                                                   IVOQ\n",
       "POLICE_RPT_YN                                                                  N\n",
       "PURCH_DT                                                                     NaN\n",
       "ORIG_OWNER_YN                                                                  N\n",
       "ANTI_BRAKES_YN                                                                 N\n",
       "CRUISE_CONT_YN                                                                 N\n",
       "NUM_CYLS                                                                     NaN\n",
       "DRIVE_TRAIN                                                                  NaN\n",
       "FUEL_SYS                                                                     NaN\n",
       "                                                     ...                        \n",
       "TRANS_TYPE                                                                   NaN\n",
       "VEH_SPEED                                                                      3\n",
       "DOT                                                                          NaN\n",
       "TIRE_SIZE                                                                    NaN\n",
       "LOC_OF_TIRE                                                                  NaN\n",
       "TIRE_FAIL_TYPE                                                               NaN\n",
       "ORIG_EQUIP_YN                                                                NaN\n",
       "MANUF_DT                                                                     NaN\n",
       "SEAT_TYPE                                                                    NaN\n",
       "RESTRAINT_TYPE                                                               NaN\n",
       "DEALER_NAME                                                                  NaN\n",
       "DEALER_TEL                                                                   NaN\n",
       "DEALER_CITY                                                                  NaN\n",
       "DEALER_STATE                                                                 NaN\n",
       "DEALER_ZIP                                                                   NaN\n",
       "PROD_TYPE                                                                      V\n",
       "REPAIRED_YN                                                                  NaN\n",
       "MEDICAL_ATTN                                                                   N\n",
       "VEHICLES_TOWED_YN                                                              N\n",
       "Adaptive_cruise_control                                                        0\n",
       "Forward_collision_warning                                                      0\n",
       "Lane_departure_warning                                                         0\n",
       "Automatic_emergency_braking                                                    0\n",
       "Blind_spot_monitoring                                                          0\n",
       "Lane_keep_system                                                               0\n",
       "Rear_visibility_camera                                                         0\n",
       "Adaptive_headlights                                                            0\n",
       "Park_assist                                                                    0\n",
       "ADAS                                                                           0\n",
       "batch                                                                          1\n",
       "Name: 2495, Length: 61, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[max(train.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "Build and manipulate some features based on the existing variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that since different car brands may have the same name of their car types, we cannot uniquely identify the model of the car without combineing the car's brand and the car's model. Therefore, we combine the brand (`MAKETXT`) and the car type (`MODELTXT`) to make sure the car's model is unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The Age of car\n",
    "data['FAILDATE'] = pd.to_datetime(data['FAILDATE'], format = \"%Y%m%d\")\n",
    "data['AGE'] = data['FAILDATE'].apply(lambda x: int(str(x)[:4])) - data['YEARTXT']\n",
    "data['AGE'] = data['AGE'].apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "#The full name of model\n",
    "data['MFR_NAME'] = data['MFR_NAME'] + data['MAKETXT']\n",
    "\n",
    "## Same model name can be used in different makes\n",
    "data['MODELTXT']=data[\"MAKETXT\"].map(str) +' '+ data[\"MODELTXT\"]\n",
    "\n",
    "#To distinguish different cities with same name\n",
    "data['CITY'] = data['CITY'] + data['STATE']\n",
    "\n",
    "#The month(the influence of season etc.) and the day(work day or weekend) of faildate.\n",
    "data['FAILDATE'] = pd.to_datetime(data['FAILDATE'], format = \"%Y%m%d\")\n",
    "data['FAILMONTH'] = data['FAILDATE'].apply(lambda x : x.month)\n",
    "data['FAILWEEKDAY'] = data['FAILDATE'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the variables that are useful in the model.\n",
    "\n",
    "`ODINO` (NHTSA's  internal reference number) is only useful for data cleaning later, we will drop this column before we fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_use = ['ODINO','MFR_NAME', 'YEARTXT', 'MAKETXT', 'MODELTXT', 'CRASH', 'FIRE', 'INJURED', 'DEATHS', 'COMPDESC', 'CITY', 'STATE', 'MILES',\n",
    "            'OCCURENCES', 'CDESCR', 'ANTI_BRAKES_YN', 'CRUISE_CONT_YN', 'VEH_SPEED', 'AGE', 'FAILMONTH', 'FAILWEEKDAY','ADAS']\n",
    "data = data[cols_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set letters in the complaint and description of components lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"CDESCR\"] = data[\"CDESCR\"].apply(lambda x : str(x).lower())\n",
    "data[\"COMPDESC\"] = data[\"COMPDESC\"].apply(lambda x : x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief description about the numeric variable to handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODINO</th>\n",
       "      <th>YEARTXT</th>\n",
       "      <th>INJURED</th>\n",
       "      <th>DEATHS</th>\n",
       "      <th>MILES</th>\n",
       "      <th>OCCURENCES</th>\n",
       "      <th>VEH_SPEED</th>\n",
       "      <th>AGE</th>\n",
       "      <th>FAILMONTH</th>\n",
       "      <th>FAILWEEKDAY</th>\n",
       "      <th>ADAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.576020e+05</td>\n",
       "      <td>157602.000000</td>\n",
       "      <td>56182.000000</td>\n",
       "      <td>53547.000000</td>\n",
       "      <td>1.291350e+05</td>\n",
       "      <td>43247.000000</td>\n",
       "      <td>104146.000000</td>\n",
       "      <td>157602.000000</td>\n",
       "      <td>157602.000000</td>\n",
       "      <td>157602.000000</td>\n",
       "      <td>157602.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.086542e+07</td>\n",
       "      <td>2013.748493</td>\n",
       "      <td>0.183404</td>\n",
       "      <td>0.008927</td>\n",
       "      <td>3.483297e+04</td>\n",
       "      <td>1.190348</td>\n",
       "      <td>30.761642</td>\n",
       "      <td>1.958091</td>\n",
       "      <td>6.379170</td>\n",
       "      <td>2.667942</td>\n",
       "      <td>0.029467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.886683e+05</td>\n",
       "      <td>1.559546</td>\n",
       "      <td>0.735022</td>\n",
       "      <td>0.494464</td>\n",
       "      <td>8.532986e+04</td>\n",
       "      <td>1.220660</td>\n",
       "      <td>29.439233</td>\n",
       "      <td>1.715441</td>\n",
       "      <td>3.321202</td>\n",
       "      <td>1.918884</td>\n",
       "      <td>0.169111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.033260e+07</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.070619e+07</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.090314e+07</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.300000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.103162e+07</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.162800e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.112407e+07</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>9.000443e+06</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ODINO        YEARTXT       INJURED        DEATHS         MILES  \\\n",
       "count  1.576020e+05  157602.000000  56182.000000  53547.000000  1.291350e+05   \n",
       "mean   1.086542e+07    2013.748493      0.183404      0.008927  3.483297e+04   \n",
       "std    1.886683e+05       1.559546      0.735022      0.494464  8.532986e+04   \n",
       "min    1.033260e+07    2012.000000      0.000000      0.000000  0.000000e+00   \n",
       "25%    1.070619e+07    2012.000000      0.000000      0.000000  5.000000e+03   \n",
       "50%    1.090314e+07    2013.000000      0.000000      0.000000  2.300000e+04   \n",
       "75%    1.103162e+07    2015.000000      0.000000      0.000000  5.162800e+04   \n",
       "max    1.112407e+07    2018.000000     99.000000     99.000000  9.000443e+06   \n",
       "\n",
       "         OCCURENCES      VEH_SPEED            AGE      FAILMONTH  \\\n",
       "count  43247.000000  104146.000000  157602.000000  157602.000000   \n",
       "mean       1.190348      30.761642       1.958091       6.379170   \n",
       "std        1.220660      29.439233       1.715441       3.321202   \n",
       "min        0.000000       0.000000       0.000000       1.000000   \n",
       "25%        1.000000       5.000000       0.000000       4.000000   \n",
       "50%        1.000000      30.000000       2.000000       6.000000   \n",
       "75%        1.000000      55.000000       3.000000       9.000000   \n",
       "max      100.000000     999.000000       6.000000      12.000000   \n",
       "\n",
       "         FAILWEEKDAY           ADAS  \n",
       "count  157602.000000  157602.000000  \n",
       "mean        2.667942       0.029467  \n",
       "std         1.918884       0.169111  \n",
       "min         0.000000       0.000000  \n",
       "25%         1.000000       0.000000  \n",
       "50%         3.000000       0.000000  \n",
       "75%         4.000000       0.000000  \n",
       "max         6.000000       1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find outliers in INJURED (number of people injured in the accident), DEATHS (number of people dead in the accident), OCCURENCES (number of the mulfunction condition occured), VEH_SPEED (the speed of the car when the accident happened).\n",
    "\n",
    "- After we sort the records by 'INJURED' and 'DEATHS', we find the record having 99 in 'INJURED' and 'DEATHS' are from one complaint, and record having 50 in 'INJURED' and 'DEATHS' are from another complaint. When we look at the content of the complaints, they are not about the desciptions of the accident, then we set the 'INJURED' and 'DEATHS' in these two records(ODINO 11101150 and 11101553) as missing.\n",
    "\n",
    "- Next, we inspect the outliers in 'OCCURENCES', we find in these records, most complaints mention the approximate occurrence times, so we keep the original values.\n",
    "\n",
    "- Finally we check the outliers in 'VEH_SPEED', we find for those records with speed greater than 140 mph, most of them are filled incorrectly based on the content of the complaint. So we set all VEH_SPEED' greater than 140 as missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.replace({'INJURED': [50,99], 'DEATHS': [50,99]}, np.nan)\n",
    "data['VEH_SPEED'] = data['VEH_SPEED'].apply(lambda x: x if x <= 140 else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ODINO                  0\n",
       "MFR_NAME               0\n",
       "YEARTXT                0\n",
       "MAKETXT                0\n",
       "MODELTXT               0\n",
       "CRASH                  0\n",
       "FIRE                   0\n",
       "INJURED           101422\n",
       "DEATHS            104057\n",
       "COMPDESC               0\n",
       "CITY                   7\n",
       "STATE                  0\n",
       "MILES              28467\n",
       "OCCURENCES        114355\n",
       "CDESCR                 0\n",
       "ANTI_BRAKES_YN       339\n",
       "CRUISE_CONT_YN       339\n",
       "VEH_SPEED          53564\n",
       "AGE                    0\n",
       "FAILMONTH              0\n",
       "FAILWEEKDAY            0\n",
       "ADAS                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For `INJURED` and `DEATHS`, we use 0 to fill the null value.\n",
    "- For `CITY`, we use a string to fill the null value.\n",
    "- For `MILES` (the miles of the car), we fill the null value with median of the `MILES` in the training set, then add some random noise from the normal distribution ranged from 0 to 3000 (we decide the noise range based on the scale of this column).\n",
    "- For `OCCURENCES`, we use 1 to fill the null value.\n",
    "- For `VEH_SPEED`, we fill the null value with the median of the `VEH_SPEED`, then add some random noise from the normal distribution ranged from 0 to 10.\n",
    "- For `MEDICAL_ATTN` (Was medical attention required) and `VEHICLES_TOWED_YN` (Was vehicle towed), since they are binary of \"Y\" (yes) and \"N\" (no), we decide to use \"N\" to fill the null value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(2333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## fill na\n",
    "data['INJURED'] = data['INJURED'].fillna(0)\n",
    "data['DEATHS'] = data['DEATHS'].fillna(0)\n",
    "data['CITY'] = data['CITY'].fillna('NA')\n",
    "data['MILES'] = data['MILES'].fillna(data[:ntrain]['MILES'].median())+np.random.normal(0,3000)\n",
    "data['VEH_SPEED'] = data['VEH_SPEED'].fillna(data[:ntrain]['VEH_SPEED'].median()) + np.random.normal(0,10)\n",
    "data['OCCURENCES'] = data['OCCURENCES'].fillna(1)\n",
    "data['ANTI_BRAKES_YN'] = data['ANTI_BRAKES_YN'].fillna('N')\n",
    "data['CRUISE_CONT_YN'] = data['CRUISE_CONT_YN'].fillna('N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data have no missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we handle duplicated rows. \n",
    "Base on the description for the dataset, we notice when a consumer reports an accident, it will create multiple records in the dataset if the consumer reports the issue on multiple components, which means we have duplicated rows but the COMPDESC(component description) are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODINO</th>\n",
       "      <th>MFR_NAME</th>\n",
       "      <th>YEARTXT</th>\n",
       "      <th>MAKETXT</th>\n",
       "      <th>MODELTXT</th>\n",
       "      <th>CRASH</th>\n",
       "      <th>FIRE</th>\n",
       "      <th>INJURED</th>\n",
       "      <th>DEATHS</th>\n",
       "      <th>COMPDESC</th>\n",
       "      <th>...</th>\n",
       "      <th>MILES</th>\n",
       "      <th>OCCURENCES</th>\n",
       "      <th>CDESCR</th>\n",
       "      <th>ANTI_BRAKES_YN</th>\n",
       "      <th>CRUISE_CONT_YN</th>\n",
       "      <th>VEH_SPEED</th>\n",
       "      <th>AGE</th>\n",
       "      <th>FAILMONTH</th>\n",
       "      <th>FAILWEEKDAY</th>\n",
       "      <th>ADAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84296</th>\n",
       "      <td>10915684</td>\n",
       "      <td>Ford Motor CompanyFORD</td>\n",
       "      <td>2015</td>\n",
       "      <td>FORD</td>\n",
       "      <td>FORD TRANSIT</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>structure:body</td>\n",
       "      <td>...</td>\n",
       "      <td>128895.290775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>i had rented the ford transit from enterprise ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>25.728497</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84297</th>\n",
       "      <td>10915684</td>\n",
       "      <td>Ford Motor CompanyFORD</td>\n",
       "      <td>2015</td>\n",
       "      <td>FORD</td>\n",
       "      <td>FORD TRANSIT</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>air bags</td>\n",
       "      <td>...</td>\n",
       "      <td>128895.290775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>i had rented the ford transit from enterprise ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>25.728497</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84298</th>\n",
       "      <td>10915684</td>\n",
       "      <td>Ford Motor CompanyFORD</td>\n",
       "      <td>2015</td>\n",
       "      <td>FORD</td>\n",
       "      <td>FORD TRANSIT</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>seats</td>\n",
       "      <td>...</td>\n",
       "      <td>128895.290775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>i had rented the ford transit from enterprise ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>25.728497</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84299</th>\n",
       "      <td>10915684</td>\n",
       "      <td>Ford Motor CompanyFORD</td>\n",
       "      <td>2015</td>\n",
       "      <td>FORD</td>\n",
       "      <td>FORD TRANSIT</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>seat belts</td>\n",
       "      <td>...</td>\n",
       "      <td>128895.290775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>i had rented the ford transit from enterprise ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>25.728497</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ODINO                MFR_NAME  YEARTXT MAKETXT      MODELTXT CRASH  \\\n",
       "84296  10915684  Ford Motor CompanyFORD     2015    FORD  FORD TRANSIT     Y   \n",
       "84297  10915684  Ford Motor CompanyFORD     2015    FORD  FORD TRANSIT     Y   \n",
       "84298  10915684  Ford Motor CompanyFORD     2015    FORD  FORD TRANSIT     Y   \n",
       "84299  10915684  Ford Motor CompanyFORD     2015    FORD  FORD TRANSIT     Y   \n",
       "\n",
       "      FIRE  INJURED  DEATHS        COMPDESC  ...           MILES OCCURENCES  \\\n",
       "84296    N      9.0     9.0  structure:body  ...   128895.290775        1.0   \n",
       "84297    N      9.0     9.0        air bags  ...   128895.290775        1.0   \n",
       "84298    N      9.0     9.0           seats  ...   128895.290775        1.0   \n",
       "84299    N      9.0     9.0      seat belts  ...   128895.290775        1.0   \n",
       "\n",
       "                                                  CDESCR  ANTI_BRAKES_YN  \\\n",
       "84296  i had rented the ford transit from enterprise ...               N   \n",
       "84297  i had rented the ford transit from enterprise ...               N   \n",
       "84298  i had rented the ford transit from enterprise ...               N   \n",
       "84299  i had rented the ford transit from enterprise ...               N   \n",
       "\n",
       "      CRUISE_CONT_YN  VEH_SPEED AGE  FAILMONTH  FAILWEEKDAY  ADAS  \n",
       "84296              N  25.728497   0         11            3     0  \n",
       "84297              N  25.728497   0         11            3     0  \n",
       "84298              N  25.728497   0         11            3     0  \n",
       "84299              N  25.728497   0         11            3     0  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an example for duplicated rows, but the COMPDESC is different\n",
    "data[data.ODINO==10915684]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One solution is to change the format of the dataset. We can create the dummies variables for COMPDESC and merge those duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop duplicated rows\n",
    "unique_odino_df = data.drop(columns = 'COMPDESC').drop_duplicates('ODINO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65                                                 air bags\n",
       "79887                      air bags: air bag control module\n",
       "2413                                  air bags: clockspring\n",
       "134291    air bags: occupant classification system - ocs...\n",
       "2778                                       air bags:frontal\n",
       "Name: COMPDESC, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the values in COMPDESC\n",
    "comp = data['COMPDESC'].drop_duplicates().sort_values()\n",
    "comp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see for `air bags: air bag control module`, it should be a part of `air bag`. If we simply get dummies variables based on the values in COMPDESC, then there are rows having 1 in  `air bags: air bag control module` but having 0 in `air bags`. To solve this problem, we split the component combination into individual components. For each row, if the an individual component was included in the combination, then we set individual component to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comp_list = []\n",
    "# for each level in COMPDESC\n",
    "for x in comp:\n",
    "    # split the component combination\n",
    "    x_split = x.split(\":\")\n",
    "    for i in x_split:\n",
    "            i = i.strip()\n",
    "            # append the individual component to the list\n",
    "            if i not in comp_list:\n",
    "                comp_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODINO</th>\n",
       "      <th>COMPDESC</th>\n",
       "      <th>comp_air bags</th>\n",
       "      <th>comp_air bag control module</th>\n",
       "      <th>comp_clockspring</th>\n",
       "      <th>comp_occupant classification system - ocs (front passenger)</th>\n",
       "      <th>comp_frontal</th>\n",
       "      <th>comp_driver side inflator module</th>\n",
       "      <th>comp_sensor/control module</th>\n",
       "      <th>comp_knee bolster</th>\n",
       "      <th>...</th>\n",
       "      <th>comp_rearview mirrors/devices</th>\n",
       "      <th>comp_exterior</th>\n",
       "      <th>comp_interior</th>\n",
       "      <th>comp_sun roof assembly</th>\n",
       "      <th>comp_windshield wiper/washer</th>\n",
       "      <th>comp_wheels</th>\n",
       "      <th>comp_cap/cover/hub</th>\n",
       "      <th>comp_center section</th>\n",
       "      <th>comp_lugs/nuts/bolts</th>\n",
       "      <th>comp_rim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10432460</td>\n",
       "      <td>steering</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10435675</td>\n",
       "      <td>vehicle speed control</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10442757</td>\n",
       "      <td>service brakes, hydraulic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10445803</td>\n",
       "      <td>electrical system</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10449316</td>\n",
       "      <td>engine and engine cooling</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 284 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ODINO                   COMPDESC  comp_air bags  \\\n",
       "0  10432460                   steering              0   \n",
       "1  10435675      vehicle speed control              0   \n",
       "2  10442757  service brakes, hydraulic              0   \n",
       "3  10445803          electrical system              0   \n",
       "4  10449316  engine and engine cooling              0   \n",
       "\n",
       "   comp_air bag control module  comp_clockspring  \\\n",
       "0                            0                 0   \n",
       "1                            0                 0   \n",
       "2                            0                 0   \n",
       "3                            0                 0   \n",
       "4                            0                 0   \n",
       "\n",
       "   comp_occupant classification system - ocs (front passenger)  comp_frontal  \\\n",
       "0                                                  0                       0   \n",
       "1                                                  0                       0   \n",
       "2                                                  0                       0   \n",
       "3                                                  0                       0   \n",
       "4                                                  0                       0   \n",
       "\n",
       "   comp_driver side inflator module  comp_sensor/control module  \\\n",
       "0                                 0                           0   \n",
       "1                                 0                           0   \n",
       "2                                 0                           0   \n",
       "3                                 0                           0   \n",
       "4                                 0                           0   \n",
       "\n",
       "   comp_knee bolster    ...     comp_rearview mirrors/devices  comp_exterior  \\\n",
       "0                  0    ...                                 0              0   \n",
       "1                  0    ...                                 0              0   \n",
       "2                  0    ...                                 0              0   \n",
       "3                  0    ...                                 0              0   \n",
       "4                  0    ...                                 0              0   \n",
       "\n",
       "   comp_interior  comp_sun roof assembly  comp_windshield wiper/washer  \\\n",
       "0              0                       0                             0   \n",
       "1              0                       0                             0   \n",
       "2              0                       0                             0   \n",
       "3              0                       0                             0   \n",
       "4              0                       0                             0   \n",
       "\n",
       "   comp_wheels  comp_cap/cover/hub  comp_center section  comp_lugs/nuts/bolts  \\\n",
       "0            0                   0                    0                     0   \n",
       "1            0                   0                    0                     0   \n",
       "2            0                   0                    0                     0   \n",
       "3            0                   0                    0                     0   \n",
       "4            0                   0                    0                     0   \n",
       "\n",
       "   comp_rim  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 284 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop exact same rows, keep rows have same ODINO but different COMPDESC\n",
    "comp_df = data[[\"ODINO\", \"COMPDESC\"]].drop_duplicates()\n",
    "\n",
    "for col in comp_list:\n",
    "    # create a new binary column for each component\n",
    "    comp_df[col] = 0\n",
    "    for i in comp_df.index:\n",
    "        # set the value to 1 if the individual component is included in COMPDESC(component combination)\n",
    "        if col in comp_df.loc[i, \"COMPDESC\"]:\n",
    "            comp_df.loc[i, col] = 1\n",
    "    # rename the column for the convenience of further analysis\n",
    "    comp_df = comp_df.rename(columns={col:\"comp_\"+col})\n",
    "    \n",
    "comp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To merge the information for duplicated rows, we group those rows, sum up all new created binary columns within the group, then delete duplicated rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODINO</th>\n",
       "      <th>comp_air bags</th>\n",
       "      <th>comp_air bag control module</th>\n",
       "      <th>comp_clockspring</th>\n",
       "      <th>comp_occupant classification system - ocs (front passenger)</th>\n",
       "      <th>comp_frontal</th>\n",
       "      <th>comp_driver side inflator module</th>\n",
       "      <th>comp_sensor/control module</th>\n",
       "      <th>comp_knee bolster</th>\n",
       "      <th>comp_on-off switch assembly</th>\n",
       "      <th>...</th>\n",
       "      <th>comp_rearview mirrors/devices</th>\n",
       "      <th>comp_exterior</th>\n",
       "      <th>comp_interior</th>\n",
       "      <th>comp_sun roof assembly</th>\n",
       "      <th>comp_windshield wiper/washer</th>\n",
       "      <th>comp_wheels</th>\n",
       "      <th>comp_cap/cover/hub</th>\n",
       "      <th>comp_center section</th>\n",
       "      <th>comp_lugs/nuts/bolts</th>\n",
       "      <th>comp_rim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10332595</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10432460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10435675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10442321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10442757</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 283 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ODINO  comp_air bags  comp_air bag control module  comp_clockspring  \\\n",
       "0  10332595              0                            0                 0   \n",
       "1  10432460              0                            0                 0   \n",
       "2  10435675              0                            0                 0   \n",
       "3  10442321              0                            0                 0   \n",
       "4  10442757              0                            0                 0   \n",
       "\n",
       "   comp_occupant classification system - ocs (front passenger)  comp_frontal  \\\n",
       "0                                                  0                       0   \n",
       "1                                                  0                       0   \n",
       "2                                                  0                       0   \n",
       "3                                                  0                       0   \n",
       "4                                                  0                       0   \n",
       "\n",
       "   comp_driver side inflator module  comp_sensor/control module  \\\n",
       "0                                 0                           0   \n",
       "1                                 0                           0   \n",
       "2                                 0                           0   \n",
       "3                                 0                           0   \n",
       "4                                 0                           0   \n",
       "\n",
       "   comp_knee bolster  comp_on-off switch assembly    ...     \\\n",
       "0                  0                            0    ...      \n",
       "1                  0                            0    ...      \n",
       "2                  0                            0    ...      \n",
       "3                  0                            0    ...      \n",
       "4                  0                            0    ...      \n",
       "\n",
       "   comp_rearview mirrors/devices  comp_exterior  comp_interior  \\\n",
       "0                              0              0              0   \n",
       "1                              0              0              0   \n",
       "2                              0              0              0   \n",
       "3                              0              0              0   \n",
       "4                              0              0              0   \n",
       "\n",
       "   comp_sun roof assembly  comp_windshield wiper/washer  comp_wheels  \\\n",
       "0                       0                             0            0   \n",
       "1                       0                             0            0   \n",
       "2                       0                             0            0   \n",
       "3                       0                             0            0   \n",
       "4                       0                             0            0   \n",
       "\n",
       "   comp_cap/cover/hub  comp_center section  comp_lugs/nuts/bolts  comp_rim  \n",
       "0                   0                    0                     0         0  \n",
       "1                   0                    0                     0         0  \n",
       "2                   0                    0                     0         0  \n",
       "3                   0                    0                     0         0  \n",
       "4                   0                    0                     0         0  \n",
       "\n",
       "[5 rows x 283 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum up all new created binary columns\n",
    "comp_df = comp_df.groupby('ODINO').sum().reset_index()\n",
    "comp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join the aggregated columns back to the remaining dataframe \n",
    "clean_data = pd.merge(unique_odino_df, comp_df, how = \"left\", on = 'ODINO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODINO</th>\n",
       "      <th>MFR_NAME</th>\n",
       "      <th>YEARTXT</th>\n",
       "      <th>MAKETXT</th>\n",
       "      <th>MODELTXT</th>\n",
       "      <th>CRASH</th>\n",
       "      <th>FIRE</th>\n",
       "      <th>INJURED</th>\n",
       "      <th>DEATHS</th>\n",
       "      <th>CITY</th>\n",
       "      <th>...</th>\n",
       "      <th>comp_rearview mirrors/devices</th>\n",
       "      <th>comp_exterior</th>\n",
       "      <th>comp_interior</th>\n",
       "      <th>comp_sun roof assembly</th>\n",
       "      <th>comp_windshield wiper/washer</th>\n",
       "      <th>comp_wheels</th>\n",
       "      <th>comp_cap/cover/hub</th>\n",
       "      <th>comp_center section</th>\n",
       "      <th>comp_lugs/nuts/bolts</th>\n",
       "      <th>comp_rim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60076</th>\n",
       "      <td>10915684</td>\n",
       "      <td>Ford Motor CompanyFORD</td>\n",
       "      <td>2015</td>\n",
       "      <td>FORD</td>\n",
       "      <td>FORD TRANSIT</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>CENTERTX</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ODINO                MFR_NAME  YEARTXT MAKETXT      MODELTXT CRASH  \\\n",
       "60076  10915684  Ford Motor CompanyFORD     2015    FORD  FORD TRANSIT     Y   \n",
       "\n",
       "      FIRE  INJURED  DEATHS      CITY    ...    comp_rearview mirrors/devices  \\\n",
       "60076    N      9.0     9.0  CENTERTX    ...                                0   \n",
       "\n",
       "       comp_exterior  comp_interior comp_sun roof assembly  \\\n",
       "60076              0              0                      0   \n",
       "\n",
       "      comp_windshield wiper/washer comp_wheels  comp_cap/cover/hub  \\\n",
       "60076                            0           0                   0   \n",
       "\n",
       "       comp_center section  comp_lugs/nuts/bolts  comp_rim  \n",
       "60076                    0                     0         0  \n",
       "\n",
       "[1 rows x 303 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether the example found before is fixed\n",
    "clean_data.loc[clean_data[\"ODINO\"] == 10915684]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data back to training set and test set, the data is ready for model building now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the index for the training set since we delete rows\n",
    "ntrain = data[:ntrain]['ODINO'].nunique()\n",
    "\n",
    "adas = clean_data[:ntrain]['ADAS']\n",
    "df = clean_data.drop(columns = ['ODINO','ADAS'])\n",
    "train = df[:ntrain]\n",
    "test = df[ntrain:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model with sklearn pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define cross validation strategy. Time series split allows the model to simulate the forecasting process based on current information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv=StratifiedKFold(n_splits=5,shuffle=True,random_state=1)\n",
    "cv = TimeSeriesSplit(n_splits=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorize different features, we are going to extract these feaures and run different transformers on them later.\n",
    "- For text features, we count the tf-idf value for the words.\n",
    "- For categorical features, we run one-hot encoding.\n",
    "- For numeric features(including the binary columns for COMPDESC), we delete empty columns to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_feats=['YEARTXT','FAILMONTH','FAILWEEKDAY']\n",
    "text_feat= ['CDESCR']\n",
    "cat_feats = set(train.dtypes[train.dtypes == \"object\"].index) - set(text_feat) | set(label_feats)\n",
    "num_feats = set(train.dtypes[train.dtypes != \"object\"].index) - set(label_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FactorExtractor are used to extract categorical features, text feature and numeric features individually in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FactorExtractor(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    In: pd.DataFrame\n",
    "        Column in that Frame\n",
    "    Out: pd.Series\n",
    "    \n",
    "    In: pd.DataFrame\n",
    "        list of Columns in that Frame\n",
    "    Out: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def transform(self, data):\n",
    "        return data.loc[:,self.factor]\n",
    "\n",
    "    def fit(self, *_):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier we get dummies variables for COMPDESC on the whole dataset, it is possible that when we train the model, there are empty columns in the training set, because information are leaked from test set to training set. To avoid data leakage, we have to delete these empty columns in each cross - validation loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ColumnDeleter(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    Delete columns with all - zero values in training set.\n",
    "    \"\"\"\n",
    "\n",
    "    def transform(self, data):\n",
    "        return data.drop(columns = self.col)\n",
    "    \n",
    "    def fit(self, data, *_):\n",
    "        self.col = data.columns[(data == 0).all()]\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneHotEncoder are used to encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = ce.OneHotEncoder(cols = cat_feats,return_df=False,use_cat_names=True,handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize NMF for non-negative matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf = NMF(init='random', random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize tfidf_vectorizer to apply stemming and english stop words on text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# allow stemming in Sklearn TfidfVectorizer\n",
    "en_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedTfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([en_stemmer.stem(w) for w in analyzer(doc)])\n",
    "\n",
    "tfidf_vectorizer= StemmedTfidfVectorizer(analyzer=\"word\", stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm = GradientBoostingClassifier(learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract categorical features, text feature and numeric features individually, run different transformer on these features within the pipeline, then we use feature union to merger these features back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catpipe=Pipeline([ ('cat_extractor',FactorExtractor(cat_feats)),\n",
    "                   ('encode', encoder)\n",
    "                  ])\n",
    "\n",
    "numpipe=Pipeline([ ('feat_extractor',FactorExtractor(num_feats)),\n",
    "                   ('deleter', ColumnDeleter())\n",
    "                  ])\n",
    "\n",
    "# extract the value in the list, so we can pass a pd series to the vectorizer, instead of a 1-column dataframe\n",
    "textpipe=Pipeline([('text_extractor', FactorExtractor(text_feat[0])),  \n",
    "                   ('tfidf',tfidf_vectorizer)\n",
    "                  ])\n",
    "\n",
    "feat_union=FeatureUnion([('text',textpipe),\n",
    "                         ('num',numpipe),\n",
    "                         ('cat',catpipe)\n",
    "                        ])\n",
    "\n",
    "\n",
    "pipe=Pipeline([ ('union',feat_union),\n",
    "                ('clf',gbm)\n",
    "              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyper parameters to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_dist=dict(union__text__tfidf__max_df=[s/float(100) for s in range(50, 90, 5)],\n",
    "                union__text__tfidf__min_df=range(1,15),\n",
    "                union__text__tfidf__ngram_range=[(1,3),(1,4),(1,5)],\n",
    "                clf__loss=['deviance','exponential'],\n",
    "                clf__n_estimators=[100,200],\n",
    "                clf__subsample=[s/float(100) for s in range(50, 101, 2)],\n",
    "                clf__max_features=[s/float(100) for s in range(1, 80, 3)],\n",
    "                clf__max_depth=range(2,5),\n",
    "                clf__min_samples_leaf=range(5,30,3),\n",
    "                clf__min_samples_split=range(5,30),\n",
    "                clf__random_state =range(1,10))\n",
    "\n",
    "model=RandomizedSearchCV(pipe,param_dist,cv=cv,n_iter=30,random_state=1,scoring=\"roc_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=5),\n",
       "          error_score='raise-deprecating',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('union', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('text', Pipeline(memory=None,\n",
       "     steps=[('text_extractor', FactorExtractor(factor='CDESCR')), ('tfidf', StemmedTfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "            dtype=<class 'numpy.float64'>, encod...    subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False))]),\n",
       "          fit_params=None, iid='warn', n_iter=30, n_jobs=None,\n",
       "          param_distributions={'union__text__tfidf__max_df': [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85], 'union__text__tfidf__min_df': range(1, 15), 'union__text__tfidf__ngram_range': [(1, 3), (1, 4), (1, 5)], 'clf__loss': ['deviance', 'exponential'], 'clf__n_estimators': [100, 200], 'clf__subsample': [0.5,...s_leaf': range(5, 30, 3), 'clf__min_samples_split': range(5, 30), 'clf__random_state': range(1, 10)},\n",
       "          pre_dispatch='2*n_jobs', random_state=1, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train,adas.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9152780538383621"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zengweihao/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/zengweihao/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/zengweihao/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/zengweihao/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/zengweihao/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/zengweihao/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/zengweihao/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([10.01019521,  9.19531717,  8.83359222,  7.21237731,  9.47651849,\n",
       "         6.49184165,  7.93178859,  6.83393288,  7.6179512 ,  9.99534721,\n",
       "         8.54557743,  8.71856599,  8.08796515,  6.68608675,  6.45961671,\n",
       "         5.93493495,  9.32043743,  6.32747722,  8.70471835,  5.99077635,\n",
       "         7.55217962,  5.65178132, 17.97966247,  6.93478193,  7.84740343,\n",
       "        30.85404611,  9.08409677,  7.06422977,  7.18138518,  7.7714447 ]),\n",
       " 'mean_score_time': array([3.69876037, 3.25313282, 2.72548862, 2.27852483, 3.07275281,\n",
       "        2.37372732, 2.64323173, 2.27663875, 2.73506021, 3.08559289,\n",
       "        3.01778913, 3.00188265, 2.92755599, 2.48504534, 2.2887794 ,\n",
       "        2.32617617, 3.00404515, 2.25999899, 2.67047582, 2.26799173,\n",
       "        2.64130673, 2.26971302, 3.07864337, 2.24097629, 2.60795317,\n",
       "        2.45079947, 3.06524806, 2.56470532, 2.70434456, 2.68933182]),\n",
       " 'mean_test_score': array([0.86682293, 0.82994413, 0.88559048, 0.88350958, 0.9042499 ,\n",
       "        0.83588829, 0.82042033, 0.89606117, 0.83820024, 0.82969947,\n",
       "        0.81864011, 0.83988852, 0.83466781, 0.83387872, 0.82855171,\n",
       "        0.8190096 , 0.84118523, 0.83109696, 0.82432774, 0.86657119,\n",
       "        0.90052806, 0.85537002, 0.91527805, 0.86694708, 0.82886864,\n",
       "        0.87551881, 0.85626633, 0.83768551, 0.83476097, 0.89235272]),\n",
       " 'mean_train_score': array([0.98656518, 0.98945717, 0.99937179, 0.99952745, 0.99541038,\n",
       "        0.99139154, 0.9818992 , 0.99963543, 0.99282812, 0.9735903 ,\n",
       "        0.966048  , 0.97288318, 0.98225011, 0.98661325, 0.98460122,\n",
       "        0.96390592, 0.98837   , 0.9815089 , 0.99840792, 0.99226307,\n",
       "        0.99900479, 0.98875255, 0.99181849, 0.99941626, 0.99045829,\n",
       "        0.99830639, 0.99022525, 0.98183944, 0.97758905, 0.98916841]),\n",
       " 'param_clf__loss': masked_array(data=['exponential', 'exponential', 'exponential',\n",
       "                    'deviance', 'deviance', 'exponential', 'exponential',\n",
       "                    'deviance', 'deviance', 'deviance', 'exponential',\n",
       "                    'exponential', 'exponential', 'deviance',\n",
       "                    'exponential', 'exponential', 'exponential',\n",
       "                    'exponential', 'deviance', 'exponential', 'deviance',\n",
       "                    'exponential', 'exponential', 'deviance',\n",
       "                    'exponential', 'deviance', 'exponential', 'deviance',\n",
       "                    'deviance', 'exponential'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__max_depth': masked_array(data=[3, 4, 4, 3, 3, 3, 2, 3, 4, 3, 3, 2, 3, 4, 2, 2, 4, 3,\n",
       "                    4, 4, 3, 4, 2, 3, 3, 3, 4, 2, 4, 3],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__max_features': masked_array(data=[0.16, 0.04, 0.46, 0.64, 0.61, 0.16, 0.64, 0.34, 0.28,\n",
       "                    0.01, 0.07, 0.4, 0.73, 0.25, 0.58, 0.58, 0.58, 0.61,\n",
       "                    0.52, 0.31, 0.25, 0.1, 0.43, 0.7, 0.52, 0.28, 0.4,\n",
       "                    0.25, 0.07, 0.76],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__min_samples_leaf': masked_array(data=[8, 29, 5, 8, 5, 20, 23, 5, 23, 26, 29, 17, 20, 29, 20,\n",
       "                    23, 17, 20, 29, 14, 8, 20, 5, 5, 17, 11, 14, 29, 29, 5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__min_samples_split': masked_array(data=[26, 17, 16, 11, 25, 7, 20, 11, 7, 25, 18, 15, 28, 7,\n",
       "                    26, 14, 26, 11, 28, 14, 15, 25, 24, 22, 26, 7, 10, 8,\n",
       "                    21, 20],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__n_estimators': masked_array(data=[100, 200, 200, 200, 100, 200, 200, 200, 100, 200, 100,\n",
       "                    100, 100, 100, 200, 100, 100, 100, 200, 100, 200, 100,\n",
       "                    200, 200, 200, 200, 100, 200, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__random_state': masked_array(data=[5, 7, 4, 8, 3, 4, 2, 1, 3, 1, 7, 8, 1, 9, 5, 5, 5, 9,\n",
       "                    2, 2, 5, 2, 8, 6, 4, 8, 6, 6, 9, 3],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__subsample': masked_array(data=[0.76, 0.56, 0.92, 0.98, 0.72, 0.72, 0.66, 0.9, 0.94,\n",
       "                    0.68, 0.66, 0.64, 0.82, 0.76, 0.92, 0.6, 0.66, 0.68,\n",
       "                    0.88, 0.98, 0.76, 1.0, 0.88, 0.8, 0.5, 0.62, 0.68,\n",
       "                    0.88, 0.72, 0.58],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_union__text__tfidf__max_df': masked_array(data=[0.75, 0.7, 0.6, 0.85, 0.75, 0.85, 0.65, 0.8, 0.75,\n",
       "                    0.55, 0.55, 0.85, 0.55, 0.85, 0.5, 0.8, 0.7, 0.6, 0.65,\n",
       "                    0.8, 0.75, 0.6, 0.7, 0.8, 0.6, 0.55, 0.5, 0.85, 0.65,\n",
       "                    0.55],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_union__text__tfidf__min_df': masked_array(data=[13, 6, 10, 10, 2, 2, 8, 4, 12, 1, 9, 11, 7, 2, 12, 5,\n",
       "                    4, 3, 9, 14, 8, 14, 1, 13, 11, 6, 8, 2, 14, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_union__text__tfidf__ngram_range': masked_array(data=[(1, 5), (1, 5), (1, 4), (1, 3), (1, 5), (1, 3), (1, 4),\n",
       "                    (1, 3), (1, 4), (1, 5), (1, 5), (1, 5), (1, 4), (1, 3),\n",
       "                    (1, 3), (1, 3), (1, 5), (1, 3), (1, 4), (1, 3), (1, 4),\n",
       "                    (1, 3), (1, 5), (1, 3), (1, 4), (1, 3), (1, 5), (1, 3),\n",
       "                    (1, 4), (1, 4)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'clf__loss': 'exponential',\n",
       "   'clf__max_depth': 3,\n",
       "   'clf__max_features': 0.16,\n",
       "   'clf__min_samples_leaf': 8,\n",
       "   'clf__min_samples_split': 26,\n",
       "   'clf__n_estimators': 100,\n",
       "   'clf__random_state': 5,\n",
       "   'clf__subsample': 0.76,\n",
       "   'union__text__tfidf__max_df': 0.75,\n",
       "   'union__text__tfidf__min_df': 13,\n",
       "   'union__text__tfidf__ngram_range': (1, 5)},\n",
       "  {'clf__loss': 'exponential',\n",
       "   'clf__max_depth': 4,\n",
       "   'clf__max_features': 0.04,\n",
       "   'clf__min_samples_leaf': 29,\n",
       "   'clf__min_samples_split': 17,\n",
       "   'clf__n_estimators': 200,\n",
       "   'clf__random_state': 7,\n",
       "   'clf__subsample': 0.56,\n",
       "   'union__text__tfidf__max_df': 0.7,\n",
       "   'union__text__tfidf__min_df': 6,\n",
       "   'union__text__tfidf__ngram_range': (1, 5)},\n",
       "  {'clf__loss': 'exponential',\n",
       "   'clf__max_depth': 4,\n",
       "   'clf__max_features': 0.46,\n",
       "   'clf__min_samples_leaf': 5,\n",
       "   'clf__min_samples_split': 16,\n",
       "   'clf__n_estimators': 200,\n",
       "   'clf__random_state': 4,\n",
       "   'clf__subsample': 0.92,\n",
       "   'union__text__tfidf__max_df': 0.6,\n",
       "   'union__text__tfidf__min_df': 10,\n",
       "   'union__text__tfidf__ngram_range': (1, 4)},\n",
       "  {'clf__loss': 'deviance',\n",
       "   'clf__max_depth': 3,\n",
       "   'clf__max_features': 0.64,\n",
       "   'clf__min_samples_leaf': 8,\n",
       "   'clf__min_samples_split': 11,\n",
       "   'clf__n_estimators': 200,\n",
       "   'clf__random_state': 8,\n",
       "   'clf__subsample': 0.98,\n",
       "   'union__text__tfidf__max_df': 0.85,\n",
       "   'union__text__tfidf__min_df': 10,\n",
       "   'union__text__tfidf__ngram_range': (1, 3)},\n",
       "  {'clf__loss': 'deviance',\n",
       "   'clf__max_depth': 3,\n",
       "   'clf__max_features': 0.61,\n",
       "   'clf__min_samples_leaf': 5,\n",
       "   'clf__min_samples_split': 25,\n",
       "   'clf__n_estimators': 100,\n",
       "   'clf__random_state': 3,\n",
       "   'clf__subsample': 0.72,\n",
       "   'union__text__tfidf__max_df': 0.75,\n",
       "   'union__text__tfidf__min_df': 2,\n",
       "   'union__text__tfidf__ngram_range': (1, 5)},\n",
       "  {'clf__loss': 'exponential',\n",
       "   'clf__max_depth': 3,\n",
       "   'clf__max_features': 0.16,\n",
       "   'clf__min_samples_leaf': 20,\n",
       "   'clf__min_samples_split': 7,\n",
       "   'clf__n_estimators': 200,\n",
       "   'clf__random_state': 4,\n",
       "   'clf__subsample': 0.72,\n",
       "   'union__text__tfidf__max_df': 0.85,\n",
       "   'union__text__tfidf__min_df': 2,\n",
       "   'union__text__tfidf__ngram_range': (1, 3)},\n",
       "  {'clf__loss': 'exponential',\n",
       "   'clf__max_depth': 2,\n",
       "   'clf__max_features': 0.64,\n",
       "   'clf__min_samples_leaf': 23,\n",
       "   'clf__min_samples_split': 20,\n",
       "   'clf__n_estimators': 200,\n",
       "   'clf__random_state': 2,\n",
       "   'clf__subsample': 0.66,\n",
       "   'union__text__tfidf__max_df': 0.65,\n",
       "   'union__text__tfidf__min_df': 8,\n",
       "   'union__text__tfidf__ngram_range': (1, 4)},\n",
       "  {'clf__loss': 'deviance',\n",
       "   'clf__max_depth': 3,\n",
       "   'clf__max_features': 0.34,\n",
       "   'clf__min_samples_leaf': 5,\n",
       "   'clf__min_samples_split': 11,\n",
       "   'clf__n_estimators': 200,\n",
       "   'clf__random_state': 1,\n",
       "   'clf__subsample': 0.9,\n",
       "   'union__text__tfidf__max_df': 0.8,\n",
       "   'union__text__tfidf__min_df': 4,\n",
       "   'union__text__tfidf__ngram_range': (1, 3)},\n",
       "  {'clf__loss': 'deviance',\n",
       "   'clf__max_depth': 4,\n",
       "   'clf__max_features': 0.28,\n",
       "   'clf__min_samples_leaf': 23,\n",
       "   'clf__min_samples_split': 7,\n",
       "   'clf__n_estimators': 100,\n",
       "   'clf__random_state': 3,\n",
       "   'clf__subsample': 0.94,\n",
       "   'union__text__tfidf__max_df': 0.75,\n",
       "   'union__text__tfidf__min_df': 12,\n",
       "   'union__text__tfidf__ngram_range': (1, 4)},\n",
       "  {'clf__loss': 'deviance',\n",
       "   'clf__max_depth': 3,\n",
       "   'clf__max_features': 0.01,\n",
       "   'clf__min_samples_leaf': 26,\n",
       "   'clf__min_samples_split': 25,\n",
       "   'clf__n_estimators': 200,\n",
       "   'clf__random_state': 1,\n",
       "   'clf__subsample': 0.68,\n",
       "   'union__text__tfidf__max_df': 0.55,\n",
       "   'union__text__tfidf__min_df': 1,\n",
       "   'union__text__tfidf__ngram_range': (1, 5)},\n",
       "  {'clf__loss': 'exponential',\n",
       "   'clf__max_depth': 3,\n",
       "   'clf__max_features': 0.07,\n",
       "   'clf__min_samples_leaf': 29,\n",
       "   'clf__min_samples_split': 18,\n",
       "   'clf__n_estimators': 100,\n",
       "   'clf__random_state': 7,\n",
       "   'clf__subsample': 0.66,\n",
       "   'union__text__tfidf__max_df': 0.55,\n",
       "   'union__text__tfidf__min_df': 9,\n",
       "   'union__text__tfidf__ngram_range': (1, 5)},\n",
       "  {'clf__loss': 'exponential',\n",
       "   'clf__max_depth': 2,\n",
       "   'clf__max_features': 0.4,\n",
       "   'clf__min_samples_leaf': 17,\n",
       "   'clf__min_samples_split': 15,\n",
       "   'clf__n_estimators': 100,\n",
       "   'clf__random_state': 8,\n",
       "   'clf__subsample': 0.64,\n",
       "   'union__text__tfidf__max_df': 0.85,\n",
       "   'union__text__tfidf__min_df': 11,\n",
       "   'union__text__tfidf__ngram_range': (1, 5)},\n",
       "  {'clf__loss': 'exponential',\n",
       "   'clf__max_depth': 3,\n",
       "   'clf__max_features': 0.73,\n",
       "   'clf__min_samples_leaf': 20,\n",
       "   'clf__min_samples_split': 28,\n",
       "   'clf__n_estimators': 100,\n",
       "   'clf__random_state': 1,\n",
       "   'clf__subsample': 0.82,\n",
       "   'union__text__tfidf__max_df': 0.55,\n",
       "   'union__text__tfidf__min_df': 7,\n",
       "   'union__text__tfidf__ngram_range': (1, 4)},\n",
       "  {'clf__loss': 'deviance',\n",
       "   'clf__max_depth': 4,\n",
       "   'clf__max_features': 0.25,\n",
       "   'clf__min_samples_leaf': 29,\n",
       "   'clf__min_samples_split': 7,\n",
       "   'clf__n_estimators': 100,\n",
       "   'clf__random_state': 9,\n",
       "   'clf__subsample': 0.76,\n",
       "   'union__text__tfidf__max_df': 0.85,\n",
       "   'union__text__tfidf__min_df': 2,\n",
       "   'union__text__tfidf__ngram_range': (1, 3)},\n",
       "  {'clf__loss': 'exponential',\n",
       "   'clf__max_depth': 2,\n",
       "   'clf__max_features': 0.58,\n",
       "   'clf__min_samples_leaf': 20,\n",
       "   'clf__min_samples_split': 26,\n",
       "   'clf__n_estimators': 200,\n",
       "   'clf__random_state': 5,\n",
       "   'clf__subsample': 0.92,\n",
       "   'union__text__tfidf__max_df': 0.5,\n",
       "   'union__text__tfidf__min_df': 12,\n",
       "   'union__text__tfidf__ngram_range': (1, 3)},\n",
       "  {'clf__loss': 'exponential',\n",
       "   'clf__max_depth': 2,\n",
       "   'clf__max_features': 0.58,\n",
       "   'clf__min_samples_leaf': 23,\n",
       "   'clf__min_samples_split': 14,\n",
       "   'clf__n_estimators': 100,\n",
       "   'clf__random_state': 5,\n",
       "   'clf__subsample': 0.6,\n",
       "   'union__text__tfidf__max_df': 0.8,\n",
       "   'union__text__tfidf__min_df': 5,\n",
       "   'union__text__tfidf__ngram_range': (1, 3)},\n",
       "  {'clf__loss': 'exponential',\n",
       "   'clf__max_depth': 4,\n",
       "   'clf__max_features': 0.58,\n",
       "   'clf__min_samples_leaf': 17,\n",
       "   'clf__min_samples_split': 26,\n",
       "   'clf__n_estimators': 100,\n",
       "   'clf__random_state': 5,\n",
       "   'clf__subsample': 0.66,\n",
       "   'union__text__tfidf__max_df': 0.7,\n",
       "   'union__text__tfidf__min_df': 4,\n",
       "   'union__text__tfidf__ngram_range': (1, 5)},\n",
       "  {'clf__loss': 'exponential',\n",
       "   'clf__max_depth': 3,\n",
       "   'clf__max_features': 0.61,\n",
       "   'clf__min_samples_leaf': 20,\n",
       "   'clf__min_samples_split': 11,\n",
       "   'clf__n_estimators': 100,\n",
       "   'clf__random_state': 9,\n",
       "   'clf__subsample': 0.68,\n",
       "   'union__text__tfidf__max_df': 0.6,\n",
       "   'union__text__tfidf__min_df': 3,\n",
       "   'union__text__tfidf__ngram_range': (1, 3)},\n",
       "  {'clf__loss': 'deviance',\n",
       "   'clf__max_depth': 4,\n",
       "   'clf__max_features': 0.52,\n",
       "   'clf__min_samples_leaf': 29,\n",
       "   'clf__min_samples_split': 28,\n",
       "   'clf__n_estimators': 200,\n",
       "   'clf__random_state': 2,\n",
       "   'clf__subsample': 0.88,\n",
       "   'union__text__tfidf__max_df': 0.65,\n",
       "   'union__text__tfidf__min_df': 9,\n",
       "   'union__text__tfidf__ngram_range': (1, 4)},\n",
       "  {'clf__loss': 'exponential',\n",
       "   'clf__max_depth': 4,\n",
       "   'clf__max_features': 0.31,\n",
       "   'clf__min_samples_leaf': 14,\n",
       "   'clf__min_samples_split': 14,\n",
       "   'clf__n_estimators': 100,\n",
       "   'clf__random_state': 2,\n",
       "   'clf__subsample': 0.98,\n",
       "   'union__text__tfidf__max_df': 0.8,\n",
       "   'union__text__tfidf__min_df': 14,\n",
       "   'union__text__tfidf__ngram_range': (1, 3)},\n",
       "  {'clf__loss': 'deviance',\n",
       "   'clf__max_depth': 3,\n",
       "   'clf__max_features': 0.25,\n",
       "   'clf__min_samples_leaf': 8,\n",
       "   'clf__min_samples_split': 15,\n",
       "   'clf__n_estimators': 200,\n",
       "   'clf__random_state': 5,\n",
       "   'clf__subsample': 0.76,\n",
       "   'union__text__tfidf__max_df': 0.75,\n",
       "   'union__text__tfidf__min_df': 8,\n",
       "   'union__text__tfidf__ngram_range': (1, 4)},\n",
       "  {'clf__loss': 'exponential',\n",
       "   'clf__max_depth': 4,\n",
       "   'clf__max_features': 0.1,\n",
       "   'clf__min_samples_leaf': 20,\n",
       "   'clf__min_samples_split': 25,\n",
       "   'clf__n_estimators': 100,\n",
       "   'clf__random_state': 2,\n",
       "   'clf__subsample': 1.0,\n",
       "   'union__text__tfidf__max_df': 0.6,\n",
       "   'union__text__tfidf__min_df': 14,\n",
       "   'union__text__tfidf__ngram_range': (1, 3)},\n",
       "  {'clf__loss': 'exponential',\n",
       "   'clf__max_depth': 2,\n",
       "   'clf__max_features': 0.43,\n",
       "   'clf__min_samples_leaf': 5,\n",
       "   'clf__min_samples_split': 24,\n",
       "   'clf__n_estimators': 200,\n",
       "   'clf__random_state': 8,\n",
       "   'clf__subsample': 0.88,\n",
       "   'union__text__tfidf__max_df': 0.7,\n",
       "   'union__text__tfidf__min_df': 1,\n",
       "   'union__text__tfidf__ngram_range': (1, 5)},\n",
       "  {'clf__loss': 'deviance',\n",
       "   'clf__max_depth': 3,\n",
       "   'clf__max_features': 0.7,\n",
       "   'clf__min_samples_leaf': 5,\n",
       "   'clf__min_samples_split': 22,\n",
       "   'clf__n_estimators': 200,\n",
       "   'clf__random_state': 6,\n",
       "   'clf__subsample': 0.8,\n",
       "   'union__text__tfidf__max_df': 0.8,\n",
       "   'union__text__tfidf__min_df': 13,\n",
       "   'union__text__tfidf__ngram_range': (1, 3)},\n",
       "  {'clf__loss': 'exponential',\n",
       "   'clf__max_depth': 3,\n",
       "   'clf__max_features': 0.52,\n",
       "   'clf__min_samples_leaf': 17,\n",
       "   'clf__min_samples_split': 26,\n",
       "   'clf__n_estimators': 200,\n",
       "   'clf__random_state': 4,\n",
       "   'clf__subsample': 0.5,\n",
       "   'union__text__tfidf__max_df': 0.6,\n",
       "   'union__text__tfidf__min_df': 11,\n",
       "   'union__text__tfidf__ngram_range': (1, 4)},\n",
       "  {'clf__loss': 'deviance',\n",
       "   'clf__max_depth': 3,\n",
       "   'clf__max_features': 0.28,\n",
       "   'clf__min_samples_leaf': 11,\n",
       "   'clf__min_samples_split': 7,\n",
       "   'clf__n_estimators': 200,\n",
       "   'clf__random_state': 8,\n",
       "   'clf__subsample': 0.62,\n",
       "   'union__text__tfidf__max_df': 0.55,\n",
       "   'union__text__tfidf__min_df': 6,\n",
       "   'union__text__tfidf__ngram_range': (1, 3)},\n",
       "  {'clf__loss': 'exponential',\n",
       "   'clf__max_depth': 4,\n",
       "   'clf__max_features': 0.4,\n",
       "   'clf__min_samples_leaf': 14,\n",
       "   'clf__min_samples_split': 10,\n",
       "   'clf__n_estimators': 100,\n",
       "   'clf__random_state': 6,\n",
       "   'clf__subsample': 0.68,\n",
       "   'union__text__tfidf__max_df': 0.5,\n",
       "   'union__text__tfidf__min_df': 8,\n",
       "   'union__text__tfidf__ngram_range': (1, 5)},\n",
       "  {'clf__loss': 'deviance',\n",
       "   'clf__max_depth': 2,\n",
       "   'clf__max_features': 0.25,\n",
       "   'clf__min_samples_leaf': 29,\n",
       "   'clf__min_samples_split': 8,\n",
       "   'clf__n_estimators': 200,\n",
       "   'clf__random_state': 6,\n",
       "   'clf__subsample': 0.88,\n",
       "   'union__text__tfidf__max_df': 0.85,\n",
       "   'union__text__tfidf__min_df': 2,\n",
       "   'union__text__tfidf__ngram_range': (1, 3)},\n",
       "  {'clf__loss': 'deviance',\n",
       "   'clf__max_depth': 4,\n",
       "   'clf__max_features': 0.07,\n",
       "   'clf__min_samples_leaf': 29,\n",
       "   'clf__min_samples_split': 21,\n",
       "   'clf__n_estimators': 100,\n",
       "   'clf__random_state': 9,\n",
       "   'clf__subsample': 0.72,\n",
       "   'union__text__tfidf__max_df': 0.65,\n",
       "   'union__text__tfidf__min_df': 14,\n",
       "   'union__text__tfidf__ngram_range': (1, 4)},\n",
       "  {'clf__loss': 'exponential',\n",
       "   'clf__max_depth': 3,\n",
       "   'clf__max_features': 0.76,\n",
       "   'clf__min_samples_leaf': 5,\n",
       "   'clf__min_samples_split': 20,\n",
       "   'clf__n_estimators': 100,\n",
       "   'clf__random_state': 3,\n",
       "   'clf__subsample': 0.58,\n",
       "   'union__text__tfidf__max_df': 0.55,\n",
       "   'union__text__tfidf__min_df': 9,\n",
       "   'union__text__tfidf__ngram_range': (1, 4)}],\n",
       " 'rank_test_score': array([10, 23,  6,  7,  2, 18, 28,  4, 16, 24, 30, 15, 20, 21, 26, 29, 14,\n",
       "        22, 27, 11,  3, 13,  1,  9, 25,  8, 12, 17, 19,  5], dtype=int32),\n",
       " 'split0_test_score': array([0.79610526, 0.66621053, 0.81878947, 0.83094737, 0.86889474,\n",
       "        0.64873684, 0.64505263, 0.87705263, 0.67515789, 0.69294737,\n",
       "        0.63368421, 0.69547368, 0.67168421, 0.68147368, 0.71205263,\n",
       "        0.66368421, 0.68610526, 0.63621053, 0.67336842, 0.81231579,\n",
       "        0.80852632, 0.77684211, 0.92236842, 0.82505263, 0.64978947,\n",
       "        0.75652632, 0.72494737, 0.70094737, 0.68305263, 0.80926316]),\n",
       " 'split0_train_score': array([0.99385417, 0.99104167, 1.        , 1.        , 1.        ,\n",
       "        0.9996875 , 0.99729167, 1.        , 0.99979167, 0.9678125 ,\n",
       "        0.9809375 , 0.9859375 , 0.995     , 0.99854167, 0.9971875 ,\n",
       "        0.98427083, 0.9990625 , 0.99729167, 1.        , 0.99958333,\n",
       "        1.        , 0.99864583, 0.9975    , 1.        , 0.99833333,\n",
       "        1.        , 0.99885417, 0.9940625 , 0.99322917, 0.99322917]),\n",
       " 'split1_test_score': array([0.84925534, 0.84930433, 0.81535371, 0.81946894, 0.81319812,\n",
       "        0.86605918, 0.83441113, 0.82157554, 0.86507937, 0.82921811,\n",
       "        0.84371938, 0.85043112, 0.82431903, 0.86194395, 0.82897315,\n",
       "        0.82549481, 0.82676857, 0.8377915 , 0.84313149, 0.84322947,\n",
       "        0.87389771, 0.85875955, 0.80913188, 0.82108564, 0.85067607,\n",
       "        0.87272193, 0.81824417, 0.86743092, 0.85126396, 0.86875367]),\n",
       " 'split1_train_score': array([0.98578534, 0.9965445 , 1.        , 1.        , 0.99685864,\n",
       "        0.99552356, 0.98651832, 1.        , 0.99646597, 0.97950262,\n",
       "        0.97272251, 0.97691099, 0.98447644, 0.98751309, 0.98753927,\n",
       "        0.96746073, 0.9913089 , 0.98282723, 1.        , 0.99146597,\n",
       "        1.        , 0.99117801, 0.99370419, 1.        , 0.99531414,\n",
       "        0.99986911, 0.99070681, 0.98751309, 0.97410995, 0.99062827]),\n",
       " 'split2_test_score': array([0.81212798, 0.84709821, 0.91765873, 0.90835813, 0.95126488,\n",
       "        0.81653026, 0.83420139, 0.92100694, 0.83984375, 0.79513889,\n",
       "        0.82738095, 0.83060516, 0.83575149, 0.81622024, 0.78701637,\n",
       "        0.81733631, 0.828187  , 0.82874504, 0.85404266, 0.78683036,\n",
       "        0.94314236, 0.83934772, 0.92255704, 0.84437004, 0.81956845,\n",
       "        0.86954365, 0.84623016, 0.79743304, 0.83878968, 0.92695933]),\n",
       " 'split2_train_score': array([0.9845566 , 0.99034503, 0.99953374, 0.99982942, 0.9949735 ,\n",
       "        0.98859372, 0.97974617, 0.99982942, 0.99152774, 0.97684627,\n",
       "        0.96376828, 0.96791912, 0.97837014, 0.98553461, 0.98090613,\n",
       "        0.95550072, 0.98616007, 0.97785839, 0.99912434, 0.9903564 ,\n",
       "        0.99905611, 0.98670594, 0.99085678, 0.99964746, 0.98820706,\n",
       "        0.99849887, 0.9864785 , 0.98053085, 0.97713058, 0.98913958]),\n",
       " 'split3_test_score': array([0.90621053, 0.87894737, 0.90731579, 0.89084211, 0.91536842,\n",
       "        0.88989474, 0.88810526, 0.89063158, 0.846     , 0.91452632,\n",
       "        0.88010526, 0.85394737, 0.87463158, 0.90031579, 0.85047368,\n",
       "        0.87073684, 0.89557895, 0.88947368, 0.85242105, 0.92247368,\n",
       "        0.90936842, 0.83442105, 0.95184211, 0.88047368, 0.87978947,\n",
       "        0.912     , 0.923     , 0.89789474, 0.88252632, 0.88347368]),\n",
       " 'split3_train_score': array([0.98563003, 0.98537593, 0.99885655, 0.99936475, 0.99339677,\n",
       "        0.98556985, 0.97407521, 0.99961885, 0.98791692, 0.97101265,\n",
       "        0.95929735, 0.96531548, 0.97468037, 0.98257416, 0.97663626,\n",
       "        0.95555608, 0.98110306, 0.97211263, 0.99684382, 0.98967556,\n",
       "        0.99824137, 0.9812836 , 0.98987282, 0.99905047, 0.98485436,\n",
       "        0.99707117, 0.98743547, 0.97440287, 0.97281809, 0.98817102]),\n",
       " 'split4_test_score': array([0.97041554, 0.90816019, 0.96883469, 0.96793135, 0.97252334,\n",
       "        0.95822042, 0.90033123, 0.97003914, 0.9649202 , 0.91666667,\n",
       "        0.90831075, 0.96898525, 0.96695273, 0.90943993, 0.9642427 ,\n",
       "        0.91779584, 0.96928636, 0.96326408, 0.8986751 , 0.96800662,\n",
       "        0.96770551, 0.96747967, 0.97049082, 0.96375339, 0.94451972,\n",
       "        0.96680217, 0.96890997, 0.92472147, 0.91817224, 0.97331376]),\n",
       " 'split4_train_score': array([0.98299977, 0.98397871, 0.99846868, 0.99844309, 0.991823  ,\n",
       "        0.98758307, 0.97186463, 0.99872888, 0.98843831, 0.97277745,\n",
       "        0.95351436, 0.96833278, 0.97872359, 0.97890274, 0.98073691,\n",
       "        0.95674123, 0.98421544, 0.97745459, 0.99607146, 0.99023409,\n",
       "        0.99772648, 0.98594938, 0.98715865, 0.99838337, 0.98558254,\n",
       "        0.99609278, 0.98765132, 0.97268787, 0.97065749, 0.98467399]),\n",
       " 'std_fit_time': array([ 3.55079676,  3.88749466,  3.99296334,  3.46042159,  4.36178979,\n",
       "         2.95017394,  3.69721424,  3.34326871,  3.53115535,  4.50132164,\n",
       "         3.93768255,  4.02124552,  3.92674319,  2.61354349,  3.04020156,\n",
       "         2.81282909,  4.30718586,  3.13053005,  4.17193096,  2.81295912,\n",
       "         3.47251123,  2.67110204,  9.1587408 ,  3.3094408 ,  3.70579917,\n",
       "        48.66135943,  4.1239527 ,  3.67842104,  3.26973647,  3.52253823]),\n",
       " 'std_score_time': array([0.44244956, 0.21955485, 0.3459735 , 0.40149345, 0.34418129,\n",
       "        0.42176981, 0.36726858, 0.44006563, 0.39169131, 0.29945237,\n",
       "        0.35637541, 0.34082398, 0.69615179, 0.45268247, 0.39879687,\n",
       "        0.40754652, 0.33434415, 0.40020772, 0.43318763, 0.39678122,\n",
       "        0.35362035, 0.39456825, 0.37723164, 0.3925695 , 0.37354654,\n",
       "        0.59921641, 0.35690338, 0.61359723, 0.42416584, 0.35356342]),\n",
       " 'std_test_score': array([0.06416223, 0.08484909, 0.05970852, 0.05415208, 0.05750775,\n",
       "        0.10410814, 0.09176763, 0.04905904, 0.09319526, 0.08325226,\n",
       "        0.09667766, 0.08708225, 0.09567479, 0.08300621, 0.08269222,\n",
       "        0.08556315, 0.09358971, 0.10854221, 0.07789998, 0.06820751,\n",
       "        0.05582193, 0.06235747, 0.05613492, 0.05276849, 0.09858956,\n",
       "        0.06908874, 0.08477388, 0.0805019 , 0.08067585, 0.05530269]),\n",
       " 'std_train_score': array([0.00377779, 0.00447659, 0.00061589, 0.00058993, 0.0028382 ,\n",
       "        0.00533143, 0.00921745, 0.00047446, 0.00462182, 0.00415319,\n",
       "        0.00973763, 0.00760601, 0.00710363, 0.00663365, 0.00719824,\n",
       "        0.01112714, 0.00629157, 0.00858938, 0.00164245, 0.00370591,\n",
       "        0.00091656, 0.00585818, 0.00352874, 0.00062219, 0.00540075,\n",
       "        0.00153449, 0.00454172, 0.00802944, 0.00809613, 0.00282193])}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__loss': 'exponential',\n",
       " 'clf__max_depth': 2,\n",
       " 'clf__max_features': 0.43,\n",
       " 'clf__min_samples_leaf': 5,\n",
       " 'clf__min_samples_split': 24,\n",
       " 'clf__n_estimators': 200,\n",
       " 'clf__random_state': 8,\n",
       " 'clf__subsample': 0.88,\n",
       " 'union__text__tfidf__max_df': 0.7,\n",
       " 'union__text__tfidf__min_df': 1,\n",
       " 'union__text__tfidf__ngram_range': (1, 5)}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the feature importance, we need to extract the feature names from each part of feature union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textpipe_names = model.best_estimator_.named_steps['union'].transformer_list[0][1].named_steps['tfidf'].get_feature_names()\n",
    "numpipe_names = model.best_estimator_.named_steps['union'].transformer_list[1][1].fit_transform(train).columns\n",
    "catpipe_names = model.best_estimator_.named_steps['union'].transformer_list[2][1].named_steps['encode'].get_dummies(train[list(cat_feats)]).columns\n",
    "col_names = list(textpipe_names) + list(catpipe_names) + list(numpipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(model.best_estimator_.named_steps['clf'].feature_importances_,\n",
    "                                   index = col_names,\n",
    "                                   columns=['importance']).sort_values('importance',\n",
    "                                                                        ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>camera</th>\n",
       "      <td>0.160875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collis</th>\n",
       "      <td>0.125415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emergency brak</th>\n",
       "      <td>0.078193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>park assist</th>\n",
       "      <td>0.072295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>automatic brak</th>\n",
       "      <td>0.065952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blind spot</th>\n",
       "      <td>0.055111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptive cruis</th>\n",
       "      <td>0.054910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adapt</th>\n",
       "      <td>0.040588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brake</th>\n",
       "      <td>0.028515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>autonom</th>\n",
       "      <td>0.026939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forward collis</th>\n",
       "      <td>0.026134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptive cruise control</th>\n",
       "      <td>0.016815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lane assist</th>\n",
       "      <td>0.016377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.015283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lane</th>\n",
       "      <td>0.014105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emerg</th>\n",
       "      <td>0.011820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>departur</th>\n",
       "      <td>0.010458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>return vehicl</th>\n",
       "      <td>0.009770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dont</th>\n",
       "      <td>0.009118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capabl</th>\n",
       "      <td>0.008567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         importance\n",
       "camera                     0.160875\n",
       "collis                     0.125415\n",
       "emergency brak             0.078193\n",
       "park assist                0.072295\n",
       "automatic brak             0.065952\n",
       "blind spot                 0.055111\n",
       "adaptive cruis             0.054910\n",
       "adapt                      0.040588\n",
       "brake                      0.028515\n",
       "autonom                    0.026939\n",
       "forward collis             0.026134\n",
       "adaptive cruise control    0.016815\n",
       "lane assist                0.016377\n",
       "acc                        0.015283\n",
       "lane                       0.014105\n",
       "emerg                      0.011820\n",
       "departur                   0.010458\n",
       "return vehicl              0.009770\n",
       "dont                       0.009118\n",
       "capabl                     0.008567"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110532, 301)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part 1 created.\n",
      "part 1 predicted\n",
      "part 2 created.\n",
      "part 2 predicted\n",
      "part 3 created.\n",
      "part 3 predicted\n",
      "part 4 created.\n",
      "part 4 predicted\n",
      "part 5 created.\n",
      "part 5 predicted\n",
      "part 6 created.\n",
      "part 6 predicted\n"
     ]
    }
   ],
   "source": [
    "# test set is too big, it will raise error on prediction\n",
    "# split the test set to serveral data sets for prediction\n",
    "test_dict = {}\n",
    "pred_dict = {}\n",
    "for i in range(1, 7):\n",
    "    test_dict['test' + str(i)] = test[20000 * (i - 1):20000 * i]\n",
    "    print('part ' + str(i) + ' created.')\n",
    "    pred_dict['prediction' + str(i)] = model.predict(test_dict['test' + str(i)])\n",
    "    print('part ' + str(i) + ' predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zengweihao/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "prediction = pred_dict['prediction1']\n",
    "for i in range(2, 7):\n",
    "    prediction = np.concatenate((prediction, pred_dict['prediction' + str(i)]), axis=None)\n",
    "\n",
    "test['prediction'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_csv('datasince2012_test_predicted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get 100 samples which have positive prediciton, then we manually review these results to test the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sample=test[test['prediction']==1].sample(n=100,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sample.to_csv('datasince2012_test_predicted_sample100.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the test set with training set, then we get all data labeled after 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zengweihao/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train['prediction'] = adas.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alldata=pd.concat([train,test])\n",
    "alldata.to_csv('datasince2012_all_labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 302)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110532, 302)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112966, 302)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "After we train the model, we refit the best test pipeline to get the document by term matrix with tf-idf values, then we may run text analysis on this matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the text pipeline with the best hyper parameter set\n",
    "best_textpipe = model.best_estimator_.steps[0][1].transformer_list[0][1]\n",
    "\n",
    "# use the best text pipeline to transform the test set\n",
    "# then we get a np arrary of tf-idf values in the document by term matrix\n",
    "text_data = best_textpipe.transform(test).toarray()\n",
    "\n",
    "# extract the word for each column\n",
    "text_cols = best_textpipe.steps[1][1].get_feature_names()\n",
    "\n",
    "# use the column name and values to create a pd dataframe\n",
    "text_df = pd.DataFrame(data = text_data, columns = text_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform NMF on document by term matrix, we need to specify the rank. Since we cannot find any resouce about scree plot for NMF, we run scree plot for SVD to simulate the rank for NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zengweihao/anaconda3/lib/python3.6/site-packages/matplotlib/legend.py:1192: MatplotlibDeprecationWarning:\n",
      "\n",
      "\n",
      "Legend.draggable() is drepecated in favor of Legend.set_draggable(). Legend.draggable may be reintroduced as a property in future releases.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAFNCAYAAADsL325AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = text_data\n",
    "num_vars=A.shape[1]\n",
    "A = np.asmatrix(A.T) * np.asmatrix(A)\n",
    "U, S, V = np.linalg.svd(A) \n",
    "eigvals = S**2 / np.cumsum(S)[-1]\n",
    "eigvals = eigvals[:20]\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "sing_vals = np.arange(20) + 1\n",
    "plt.plot(sing_vals, eigvals, 'ro-', linewidth=2)\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Eigenvalue')\n",
    "leg = plt.legend(['Eigenvalues from SVD'], loc='best', borderpad=0.3, \n",
    "                 shadow=False, prop=matplotlib.font_manager.FontProperties(size='small'),\n",
    "                 markerscale=0.4)\n",
    "leg.get_frame().set_alpha(0.4)\n",
    "leg.draggable(state=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot, we can see the eigenvalue converges when the number of component reaches 3 or 4, indicating 3 or 4 can be a good number of components for matrix fatorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to print the words for each topic from NMF, and we may try different number of components around 4 to check whether the topic make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from time import time\n",
    "\n",
    "n_components = 3\n",
    "n_top_words = 20\n",
    "\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "dataset = test\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Use tf-idf features for NMF.\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "t0 = time()\n",
    "tfidf = best_textpipe.transform(dataset)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model (Frobenius norm) with tf-idf features \n",
      "done in 16.710s.\n",
      "\n",
      "Topics in NMF model (Frobenius norm):\n",
      "Topic #0: failur vehicl contact mileag tl own manufactur approxim diagnos repair notifi 000 taken state dealer warn mph 2012 illumin 2013\n",
      "Topic #1: car light drive problem vehicl time start engin turn issu stop happen steer brake power dealership tr mile recal park\n",
      "Topic #2: contact recal part repair manufactur campaign nhtsa receiv number avail notif exceed unavail experienc reason state tl own confirm bag\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_components = 3\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (Frobenius norm) with tf-idf features \")\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model (Frobenius norm):\")\n",
    "tfidf_feature_names = best_textpipe.steps[1][1].get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model (Frobenius norm) with tf-idf features \n",
      "done in 12.193s.\n",
      "\n",
      "Topics in NMF model (Frobenius norm):\n",
      "Topic #0: failur vehicl contact mileag tl own manufactur approxim diagnos repair notifi 000 taken state dealer warn mph 2012 illumin 2013\n",
      "Topic #1: car drive light problem vehicl engin start time turn issu stop steer happen brake power dealership acceler mile tr recal\n",
      "Topic #2: contact recal part repair manufactur campaign nhtsa receiv number avail notif exceed unavail experienc reason state tl own confirm bag\n",
      "Topic #3: door ajar close latch lock open driver light stay passeng interior ford unlock rear dome sensor shut seat handl remain\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_components = 4\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (Frobenius norm) with tf-idf features \")\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model (Frobenius norm):\")\n",
    "tfidf_feature_names = best_textpipe.steps[1][1].get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model (Frobenius norm) with tf-idf features \n",
      "done in 17.205s.\n",
      "\n",
      "Topics in NMF model (Frobenius norm):\n",
      "Topic #0: failur vehicl contact mileag tl own manufactur approxim diagnos repair notifi 000 taken state dealer warn mph 2012 illumin 2013\n",
      "Topic #1: car drive engin problem start light time turn vehicl stop issu steer happen power brake acceler dealership mile transmiss park\n",
      "Topic #2: contact repair part recal manufactur campaign nhtsa receiv number notif avail exceed unavail experienc reason state tl own confirm failur\n",
      "Topic #3: door ajar close latch lock open driver light stay interior ford passeng unlock dome shut rear sensor handl remain batteri\n",
      "Topic #4: airbag air bag seat passeng recal deploy takata belt driver crack light vehicl tire did crash injuri rear accid safeti\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_components = 5\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (Frobenius norm) with tf-idf features \")\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model (Frobenius norm):\")\n",
    "tfidf_feature_names = best_textpipe.steps[1][1].get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model (Frobenius norm) with tf-idf features \n",
      "done in 15.303s.\n",
      "\n",
      "Topics in NMF model (Frobenius norm):\n",
      "Topic #0: failur vehicl contact mileag tl own manufactur approxim diagnos repair notifi 000 taken state dealer mph warn 2012 illumin 2013\n",
      "Topic #1: car engin start drive problem time light stop vehicl issu brake happen acceler transmiss dealership turn park mile tr dealer\n",
      "Topic #2: contact repair part recal manufactur campaign nhtsa receiv number notif avail exceed unavail experienc reason state tl own confirm failur\n",
      "Topic #3: door ajar close latch lock open driver light stay interior ford passeng unlock dome shut rear sensor handl remain batteri\n",
      "Topic #4: airbag air bag seat passeng recal deploy takata belt driver crack light tire vehicl did crash injuri rear accid safeti\n",
      "Topic #5: steer power wheel turn drive assist lock lost control difficult loss right left vehicl ford make warn highway road fault\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_components = 6\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (Frobenius norm) with tf-idf features \")\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model (Frobenius norm):\")\n",
    "tfidf_feature_names = best_textpipe.steps[1][1].get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
